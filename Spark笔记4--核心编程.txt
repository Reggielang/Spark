四、核心编程
1、RDD--适合并行计算，和重复使用
Spark计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。三大数据结构分别是：
RDD : 弹性分布式数据集（RDD，是一个计算模型，不是数据模型，里面封装了计算逻辑）
累加器：分布式共享只写变量
广播变量：分布式共享只读变量

RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。

RDD的弹性是指：
存储的弹性：内存与磁盘的自动切换；
容错的弹性：数据丢失可以自动恢复；
计算的弹性：计算出错重试机制；
分片的弹性：可根据需要重新分片。
分布式：数据存储在大数据集群不同节点上
数据集：RDD封装了计算逻辑，并不保存数据
数据抽象：RDD是一个抽象类，需要子类具体实现
不可变：RDD封装了计算逻辑，是不可以改变的，想要改变，只能产生新的RDD，在新的RDD里面封装计算逻辑
可分区、并行计算

！！注意：RDD是一个数据结构，类似于链表中的node，RDD中有适合并行计算的分区操作，RDD中封装了最小的计算单元，目的是更适合重复使用，spark的计算主要就是通过组合RDD的操作完成需求

2、RDD存在的主要功能：
RDD功能的组合采用了装饰者设计模式：用于扩展功能
RDD中的collect方法类似于IO中的read方法
IO：输入，输出（字节流，字符流）
！！RDD不存储任何数据，只封装逻辑！！

3、RDD核心属性
 *  - A list of partitions
 *  - A function for computing each split
 *  - A list of dependencies on other RDDs
 *  - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
 *  - Optionally, a list of preferred locations to compute each split on (e.g. block locations for
 *    an HDFS file)

数据和计算的位置在同一个进程上称为进程本地化
数据和计算的位置在同一个节点上称为节点本地化
数据和计算的位置在同一个机架上称为机架本地化
移动数据不如移动计算

4、执行原理
从计算的角度来讲，数据处理过程中需要计算资源（内存 & CPU）和计算模型（逻辑）。执行时，需要将计算资源和计算模型进行协调和整合。
Spark框架在执行时，先申请资源，然后将应用程序的数据处理逻辑分解成一个一个的计算任务。然后将任务发到已经分配资源的计算节点上, 按照指定的计算模型进行数据计算。最后得到计算结果。

1)启动Yarn集群环境
2)Spark通过申请资源创建调度节点和计算节点
3)Spark框架根据需求将计算逻辑根据分区划分成不同的任务
4)调度节点将任务根据计算节点状态发送到对应的计算节点进行计算

5、RDD创建
1)从集合（内存）中创建RDD
从集合中创建RDD，Spark主要提供了两个方法：parallelize和makeRDD
2)从外部存储（文件）创建RDD
由外部存储系统的数据集创建RDD包括：本地的文件系统，所有Hadoop支持的数据集，比如HDFS、HBase等
3)从其他RDD创建
主要是通过一个RDD运算完后，再产生新的RDD。
4)直接创建RDD（new）
使用new的方式直接构造RDD，一般由Spark框架自身使用。

6、RDD并行度与分区
默认情况下，Spark可以将一个作业切分多个任务后，发送给Executor节点并行计算，而能够并行计算的任务数量我们称之为并行度。这个数量可以在构建RDD时指定。记住，这里的并行执行的任务数量，并不是指的切分任务的数量，不要混淆了。
读取内存数据时，数据可以按照并行度的设定进行数据的分区操作
读取文件数据时，数据是按照Hadoop文件读取的规则进行切片分区，而切片规则和数据读取的规则有些差异


7、RDD方法分为2大类
1.逻辑封装，将旧逻辑转换成新的逻辑 称为转换算子
2.执行逻辑，将封装好的逻辑开始执行，让整个作业执行起来 称为行动算子

RDD转换算子（将RDD的方法称为算子的原因：为了和Scala集合的方法进行区分）
  RDD根据数据处理方式的不同将算子整体上分为Value类型、双Value类型和Key-Value类型
  在RDD进行转换时，新的RDD和旧的RDD分区数量保持一致
  数据处理过程中，默认的分区不变
  数据执行顺序 数据处理过程中，遵循分区内有序，分区间无序
  RDD其实就是封装了逻辑，所以如果有多个RDD逻辑，那么第一条数据应该执行完所有的逻辑之后第二条数据才能执行

1) def map[U: ClassTag](f: T => U): RDD[U]
将处理的数据逐条进行映射转换，这里的转换可以是类型的转换，也可以是值的转换

2)def mapPartitions[U: ClassTag](
    f: Iterator[T] => Iterator[U],
    preservesPartitioning: Boolean = false): RDD[U]
将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据

3)def mapPartitionsWithIndex[U: ClassTag](
  f: (Int, Iterator[T]) => Iterator[U],preservesPartitioning: Boolean = false): RDD[U]
将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据，在处理时同时可以获取当前分区索引。

4)def flatMap[U: ClassTag](f: T => TraversableOnce[U]): RDD[U]
将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射

5)def glom(): RDD[Array[T]]
将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变

6)def groupBy[K](f: T => K)(implicit kt: ClassTag[K]): RDD[(K, Iterable[T])]
将数据根据指定的规则进行分组, 分区默认不变，但是数据会被打乱重新组合，我们将这样的操作称之为shuffle。极限情况下，数据可能被分在同一个分区中
spark要求一个组的数据在一个分区中，但是并不是说一个分区中只有一个组
shuffle操作不允许在内存中等待，必须落盘（shuffle会将完整的计算过程一分为二，形成两个阶段，一阶段用于写数据，二阶段用于读数据，写数据阶段如果没有完成，读数据阶段不能执行）
shuffle操作可以更改分区

