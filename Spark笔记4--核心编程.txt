四、核心编程
1、RDD--适合并行计算，和重复使用
Spark计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。三大数据结构分别是：
RDD : 弹性分布式数据集（RDD，是一个计算模型，不是数据模型，里面封装了计算逻辑）
累加器：分布式共享只写变量
广播变量：分布式共享只读变量

RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。

RDD的弹性是指：
存储的弹性：内存与磁盘的自动切换；
容错的弹性：数据丢失可以自动恢复；
计算的弹性：计算出错重试机制；
分片的弹性：可根据需要重新分片。
分布式：数据存储在大数据集群不同节点上
数据集：RDD封装了计算逻辑，并不保存数据
数据抽象：RDD是一个抽象类，需要子类具体实现
不可变：RDD封装了计算逻辑，是不可以改变的，想要改变，只能产生新的RDD，在新的RDD里面封装计算逻辑
可分区、并行计算

！！注意：RDD是一个数据结构，类似于链表中的node，RDD中有适合并行计算的分区操作，RDD中封装了最小的计算单元，目的是更适合重复使用，spark的计算主要就是通过组合RDD的操作完成需求

2、RDD存在的主要功能：
RDD功能的组合采用了装饰者设计模式：用于扩展功能
RDD中的collect方法类似于IO中的read方法
IO：输入，输出（字节流，字符流）
！！RDD不存储任何数据，只封装逻辑！！

3、RDD核心属性
 *  - A list of partitions
 *  - A function for computing each split
 *  - A list of dependencies on other RDDs
 *  - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
 *  - Optionally, a list of preferred locations to compute each split on (e.g. block locations for
 *    an HDFS file)


RDD分区：
RDD为了能够快速并行计算，防止一个Executor过载，在RDD中创建了一个类似管道的东西，将数据进行了分区

数据和计算的位置在同一个进程上称为进程本地化
数据和计算的位置在同一个节点上称为节点本地化
数据和计算的位置在同一个机架上称为机架本地化
移动数据不如移动计算

4、执行原理
从计算的角度来讲，数据处理过程中需要计算资源（内存 & CPU）和计算模型（逻辑）。执行时，需要将计算资源和计算模型进行协调和整合。
Spark框架在执行时，先申请资源，然后将应用程序的数据处理逻辑分解成一个一个的计算任务。然后将任务发到已经分配资源的计算节点上, 按照指定的计算模型进行数据计算。最后得到计算结果。

1)启动Yarn集群环境
2)Spark通过申请资源创建调度节点和计算节点
3)Spark框架根据需求将计算逻辑根据分区划分成不同的任务
4)调度节点将任务根据计算节点状态发送到对应的计算节点进行计算

5、RDD创建
1)从集合（内存）中创建RDD
从集合中创建RDD，Spark主要提供了两个方法：parallelize和makeRDD
2)从外部存储（文件）创建RDD
由外部存储系统的数据集创建RDD包括：本地的文件系统，所有Hadoop支持的数据集，比如HDFS、HBase等
3)从其他RDD创建
主要是通过一个RDD运算完后，再产生新的RDD。
4)直接创建RDD（new）
使用new的方式直接构造RDD，一般由Spark框架自身使用。

6、RDD并行度与分区
默认情况下，Spark可以将一个作业切分多个任务后，发送给Executor节点并行计算，而能够并行计算的任务数量我们称之为并行度。这个数量可以在构建RDD时指定。记住，这里的并行执行的任务数量，并不是指的切分任务的数量，不要混淆了。
读取内存数据时，数据可以按照并行度的设定进行数据的分区操作
读取文件数据时，数据是按照Hadoop文件读取的规则进行切片分区，而切片规则和数据读取的规则有些差异


7、RDD方法分为2大类
1.逻辑封装，将旧逻辑转换成新的逻辑 称为转换算子
2.执行逻辑，将封装好的逻辑开始执行，让整个作业执行起来 称为行动算子

RDD转换算子（将RDD的方法称为算子的原因：为了和Scala集合的方法进行区分）
  RDD根据数据处理方式的不同将算子整体上分为Value类型、双Value类型和Key-Value类型
  在RDD进行转换时，新的RDD和旧的RDD分区数量保持一致
  数据处理过程中，默认的分区不变
  数据执行顺序 数据处理过程中，遵循分区内有序，分区间无序
  RDD其实就是封装了逻辑，所以如果有多个RDD逻辑，那么第一条数据应该执行完所有的逻辑之后第二条数据才能执行

1) def map[U: ClassTag](f: T => U): RDD[U]
将处理的数据逐条进行映射转换，这里的转换可以是类型的转换，也可以是值的转换

2)def mapPartitions[U: ClassTag](
    f: Iterator[T] => Iterator[U],
    preservesPartitioning: Boolean = false): RDD[U]
将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据

3)def mapPartitionsWithIndex[U: ClassTag](
  f: (Int, Iterator[T]) => Iterator[U],preservesPartitioning: Boolean = false): RDD[U]
将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据，在处理时同时可以获取当前分区索引。

4)def flatMap[U: ClassTag](f: T => TraversableOnce[U]): RDD[U]
将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射

5)def glom(): RDD[Array[T]]
将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变

！注意：shuffle表示一个分区的数据被打乱后和其他分区的数据重新组合在一起！
6)def groupBy[K](f: T => K)(implicit kt: ClassTag[K]): RDD[(K, Iterable[T])]
将数据根据指定的规则进行分组, 分区默认不变，但是数据会被打乱重新组合，极限情况下，数据可能被分在同一个分区中
spark要求一个组的数据在一个分区中，但是并不是说一个分区中只有一个组
shuffle操作不允许在内存中等待，必须落盘（shuffle会将完整的计算过程一分为二，形成两个阶段，一阶段用于写数据，二阶段用于读数据，写数据阶段如果没有完成，读数据阶段不能执行）
shuffle操作可以更改分区

7)filterdef filter(f: T => Boolean): RDD[T]
将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃。
当数据进行筛选过滤后，分区不变，但是分区内的数据可能不均衡，生产环境下，可能会出现数据倾斜。

8)def sample(
  withReplacement: Boolean,
  fraction: Double,
  seed: Long = Utils.random.nextLong): RDD[T]
根据指定的规则从数据集中抽取数据

9)def distinct()(implicit ord: Ordering[T] = null): RDD[T]
def distinct(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]
将数据集中重复的数据去重

10)def coalesce(numPartitions: Int, shuffle: Boolean = false,
           partitionCoalescer: Option[PartitionCoalescer] = Option.empty)
          (implicit ord: Ordering[T] = null): RDD[T]
根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率
当spark程序中，存在过多的小任务的时候，可以通过coalesce方法，收缩合并分区，减少分区的个数，减小任务调度成本

11)def repartition(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]
该操作内部其实执行的是coalesce操作，参数shuffle的默认值为true。无论是将分区数多的RDD转换为分区数少的RDD，还是将分区数少的RDD转换为分区数多的RDD，repartition操作都可以完成，因为无论如何都会经shuffle过程。

12) sortBy[K](f: (T) => K,ascending: Boolean = true, numPartitions: Int = this.partitions.length)
  (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T]
该操作用于排序数据。在排序之前，可以将数据通过f函数进行处理，之后按照f函数处理的结果进行排序，默认为升序排列。排序后新产生的RDD的分区数与原RDD的分区数一致。中间存在shuffle的过程

双Value类型

13)def intersection(other: RDD[T]): RDD[T]
对源RDD和参数RDD求交集后返回一个新的RDD
14)uniondef union(other: RDD[T]): RDD[T]
对源RDD和参数RDD求并集后返回一个新的RDD
15)def subtract(other: RDD[T]): RDD[T]
以一个RDD元素为主，去除两个RDD中重复元素，将其他元素保留下来。求差集

16)def zip[U: ClassTag](other: RDD[U]): RDD[(T, U)]
将两个RDD中的元素，以键值对的形式进行合并。其中，键值对中的Key为第1个RDD中的元素，Value为第2个RDD中的相同位置的元素。

Key - Value类型
17)def partitionBy(partitioner: Partitioner): RDD[(K, V)]
将数据按照指定Partitioner重新进行分区。Spark默认的分区器是HashPartitioner

18)
def reduceByKey(func: (V, V) => V): RDD[(K, V)]
def reduceByKey(func: (V, V) => V, numPartitions: Int): RDD[(K, V)]
可以将数据按照相同的Key对Value进行聚合

19）def groupByKey(): RDD[(K, Iterable[V])]
def groupByKey(numPartitions: Int): RDD[(K, Iterable[V])]
def groupByKey(partitioner: Partitioner): RDD[(K, Iterable[V])]
将数据源的数据根据key对value进行分组

从shuffle的角度：reduceByKey和groupByKey都存在shuffle的操作，但是reduceByKey可以在shuffle前对分区内相同key的数据进行预聚合（combine）功能，这样会减少落盘的数据量，而groupByKey只是进行分组，不存在数据量减少的问题，reduceByKey性能比较高。
从功能的角度：reduceByKey其实包含分组和聚合的功能。groupByKey只能分组，不能聚合，所以在分组聚合的场合下，推荐使用reduceByKey，如果仅仅是分组而不需要聚合。那么还是只能使用groupByKey

20)def aggregateByKey[U: ClassTag](zeroValue: U)(seqOp: (U, V) => U, combOp: (U, U) => U): RDD[(K, U)]
将数据根据不同的规则进行分区内计算和分区间计算

21)def foldByKey(zeroValue: V)(func: (V, V) => V): RDD[(K, V)]
当分区内计算规则和分区间计算规则相同时，aggregateByKey就可以简化为foldByKey

22)def combineByKey[C](
  createCombiner: V => C,
  mergeValue: (C, V) => C,
  mergeCombiners: (C, C) => C): RDD[(K, C)]

最通用的对key-value型rdd进行聚集操作的聚集函数（aggregation function）。类似于aggregate()，combineByKey()允许用户返回值的类型与输入不一致。

reduceByKey: 相同key的第一个数据不进行任何计算，分区内和分区间计算规则相同
foldByKey: 相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则相同
aggregateByKey：相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则可以不相同
combineByKey:当计算时，发现数据结构不满足要求时，可以让第一个数据转换结构。分区内和分区间计算规则不相同。


23)def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.length) : RDD[(K, V)]
在一个(K,V)的RDD上调用，K必须实现Ordered接口(特质)，返回一个按照key进行排序的

24)def join[W](other: RDD[(K, W)]): RDD[(K, (V, W))]
在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素连接在一起的(K,(V,W))的RDD

25)def leftOuterJoin[W](other: RDD[(K, W)]): RDD[(K, (V, Option[W]))]
类似于SQL语句的左外连接

26)def cogroup[W](other: RDD[(K, W)]): RDD[(K, (Iterable[V], Iterable[W]))]
在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable<V>,Iterable<W>))类型的RDD

WordCount 先统计减少数据量之后再分组！！！
